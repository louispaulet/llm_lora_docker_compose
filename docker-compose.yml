version: '3'

services:
  llama-finetuning:
    build:
      context: .
      dockerfile: Dockerfile
    volumes:
      - ./project:/workspace:rw
    ports:
      - "8888:8888"
    deploy:
          resources:
            reservations:
              devices:
                - driver: nvidia
                  count: 1
                  capabilities: [gpu]